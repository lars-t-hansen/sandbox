// Code generated by goyacc grammar.y. DO NOT EDIT.

//line grammar.y:2
package compiler

import __yyfmt__ "fmt"

//line grammar.y:2

import (
	"fmt"
	"io"
	"strconv"
)

type astVar struct {
	lineno int
	name   string
	index  int
}

type astAtom struct {
	lineno int
	name   string
}

type astNumber struct {
	lineno int
	value  int64
}

type astStruct struct {
	lineno     int
	name       string
	components []astTerm
}

// type astTerm union {
//   *astAtom
//   *astNumber
//   *astStruct
//   *astVar
// }

type astTerm interface {
	fmt.Stringer
	line() int
}

type astQuery struct {
	vars []*astVar
	body []astTerm
}

type astFact struct {
	head astTerm
}

type astRule struct {
	vars []*astVar
	head astTerm
	body []astTerm
}

// type astPhrase union {
//   *astFact
//   *astRule
//   *astQuery
//   nil
// }

type astPhrase interface {
	fmt.Stringer
	line() int
}

//line grammar.y:72
type yySymType struct {
	yys     int
	name    string
	terms   []astTerm
	term    astTerm
	phrases []astPhrase
	phrase  astPhrase
}

const T_ATOM = 57346
const T_NUMBER = 57347
const T_VARNAME = 57348
const T_INFIX_OP = 57349
const T_LPAREN = 57350
const T_RPAREN = 57351
const T_COMMA = 57352
const T_PERIOD = 57353
const T_FACT_OP = 57354
const T_QUERY_OP = 57355

var yyToknames = [...]string{
	"$end",
	"error",
	"$unk",
	"T_ATOM",
	"T_NUMBER",
	"T_VARNAME",
	"T_INFIX_OP",
	"T_LPAREN",
	"T_RPAREN",
	"T_COMMA",
	"T_PERIOD",
	"T_FACT_OP",
	"T_QUERY_OP",
}

var yyStatenames = [...]string{}

const yyEofCode = 1
const yyErrCode = 2
const yyInitialStackSize = 16

//line grammar.y:169

/////////////////////////////////////////////////////////////////////////////////////////////////
//
// AST

func (n *astVar) String() string {
	return fmt.Sprintf("[%s %d]", n.name, n.index)
}

func (n *astVar) line() int {
	return n.lineno
}

func (n *astAtom) String() string {
	return n.name
}

func (n *astAtom) line() int {
	return n.lineno
}

func (n *astNumber) String() string {
	return fmt.Sprint(n.value)
}

func (n *astNumber) line() int {
	return n.lineno
}

func (n *astStruct) String() string {
	args := ""
	for _, c := range n.components {
		if args != "" {
			args = args + ","
		}
		args = args + c.String()
	}
	return n.name + "(" + args + ")"
}

func (n *astStruct) line() int {
	return n.lineno
}

func (f *astQuery) String() string {
	return "?- " + termsToString(f.body) + "."
}

func (f *astQuery) line() int {
	return f.body[0].line()
}

func (f *astFact) String() string {
	return ":-" + f.head.String() + "."
}

func (f *astFact) line() int {
	return f.head.line()
}

func (f *astRule) String() string {
	return f.head.String() + " :- " + termsToString(f.body) + "."
}

func (f *astRule) line() int {
	return f.head.line()
}

func termsToString(ts []astTerm) string {
	s := ""
	for _, term := range ts {
		if s != "" {
			s = s + ", "
		}
		s = s + term.String()
	}
	return s
}

/////////////////////////////////////////////////////////////////////////////////////////////////
//
// Tokenizer

type reader interface {
	ReadRune() (rune, int, error)
	UnreadRune() error
}

type tokenizer2 struct {
	// Input characters
	input reader

	// Line number at start of previous token returned
	lineno int

	// The rest of this is parser context, see parser code further down.
	ctx *parserctx
}

func newTokenizer2(r reader, ctx *parserctx) *tokenizer2 {
	return &tokenizer2{
		input:  r,
		lineno: 0,
		ctx:    ctx,
	}
}

func (l *tokenizer2) Lex(lval *yySymType) int {
	t, name := l.get()
	lval.name = name
	return t
}

func (l *tokenizer2) Error(s string) {
	panic(s)
}

func lineno(l yyLexer) int {
	return l.(*tokenizer2).lineno
}

func (t *tokenizer2) peekChar() rune {
	r, _, err := t.input.ReadRune()
	if err == io.EOF {
		return -1
	}
	if err != nil {
		panic(fmt.Sprintf("Line %d: Bad input: "+err.Error(), t.lineno))
	}
	t.input.UnreadRune()
	return r
}

func (t *tokenizer2) getChar() rune {
	r, _, err := t.input.ReadRune()
	if err == io.EOF {
		return -1
	}
	if err != nil {
		panic(fmt.Sprintf("Line %d: Bad input: "+err.Error(), t.lineno))
	}
	return r
}

func (t *tokenizer2) get() (int, string) {
outer:
	for {
		r := t.getChar()
		if r == -1 {
			return -1, ""
		}
		if r == '\t' || r == ' ' {
			continue
		}
		if r == '\n' {
			t.lineno++
			continue
		}
		if r == '/' && t.peekChar() == '*' {
			t.getChar()
			for {
				r := t.getChar()
				if r == -1 {
					panic(fmt.Sprintf("Line %d: EOF in comment", t.lineno))
				}
				if r == '*' && t.peekChar() == '/' {
					t.getChar()
					continue outer
				}
				if r == '\n' {
					t.lineno++
				}
			}
		}
		if r == '(' {
			return T_LPAREN, ""
		}
		if r == ')' {
			return T_RPAREN, ""
		}
		if r == '.' {
			return T_PERIOD, ""
		}
		if r == ',' {
			return T_COMMA, ""
		}
		if r == '-' {
			if isDigitChar(t.peekChar()) {
				return T_NUMBER, t.lexWhile(isDigitChar, "-")
			}
		}
		if r == '\'' {
			name := t.lexWhile(func(r rune) bool {
				return r != -1 && r != '\'' && r != '\n' && r != '\r'
			}, "")
			if t.getChar() != '\'' {
				panic(fmt.Sprintf("Line %d: unterminated quoted atom", t.lineno))
			}
			return T_ATOM, name
		}
		if isOperatorChar(r) {
			name := t.lexWhile(isOperatorChar, string(r))
			if name == "?-" {
				return T_QUERY_OP, ""
			}
			if name == ":-" {
				return T_FACT_OP, ""
			}
			return T_INFIX_OP, name
		}
		if isDigitChar(r) {
			return T_NUMBER, t.lexWhile(isDigitChar, string(r))
		}
		if isVarFirstChar(r) {
			return T_VARNAME, t.lexWhile(isAtomNextChar, string(r))
		}
		if isAtomFirstChar(r) {
			// TODO: This strikes me as a hack, there should be a more principled solution
			// to this somewhere.
			name := t.lexWhile(isAtomNextChar, string(r))
			if name == "is" {
				return T_INFIX_OP, name
			}
			return T_ATOM, name
		}
		panic(fmt.Sprintf("Line %d: bad character: %v", t.lineno, r))
	}
}

// This depends on isChar() being false for -1 and newlines
func (t *tokenizer2) lexWhile(isChar func(r rune) bool, s string) string {
	for isChar(t.peekChar()) {
		s = s + string(t.getChar())
	}
	return s
}

func isOperatorChar(r rune) bool {
	return r == '+' || r == '-' || r == '?' || r == ':' || r == '!' || r == '='
}

func isDigitChar(r rune) bool {
	return r >= '0' && r <= '9'
}

func isAtomFirstChar(r rune) bool {
	return r >= 'a' && r <= 'z'
}

func isVarFirstChar(r rune) bool {
	return r >= 'A' && r <= 'Z' || r == '_'
}

func isAtomNextChar(r rune) bool {
	return r >= 'a' && r <= 'z' || r >= 'A' && r <= 'Z' || r == '_' || r >= '0' && r <= '9'
}

/////////////////////////////////////////////////////////////////////////////////////////////////
//
// Parser interface

// An alternative here would be to pass in a callback and for the grammar to act on each phrase
// as it is encountered.  That might also play a little better in an interactive system.

// Sticking parser context on yylex is how the cool kids do it, but it's really not pretty.

type parserctx struct {
	// Next index for a variable in the clause
	varIndex int

	// All unique variables in the current clause.
	vars []*astVar

	nameMap map[string]int

	// Set to the slice of phrases when the parse succeeds
	result []astPhrase
}

func parsePhrases(r reader) []astPhrase {
	ctx := &parserctx{
		varIndex: 0,
		vars:     make([]*astVar, 0),
		nameMap:  make(map[string]int, 0),
	}
	t := newTokenizer2(r, ctx)
	if yyParse(t) == 0 {
		return ctx.result
	}
	panic("Parse failed")
}

func setResult(l yyLexer, r []astPhrase) {
	l.(*tokenizer2).ctx.result = r
}

func newVariable(l yyLexer, name string) *astVar {
	t := l.(*tokenizer2)
	p := t.ctx
	if name == "_" {
		// Fresh anonymous variable
		index := p.varIndex
		p.varIndex++
		v := &astVar{t.lineno, name, index}
		p.vars = append(p.vars, v)
		return v
	}

	index, found := p.nameMap[name]
	if found {
		// Previously seen variable
		return &astVar{t.lineno, name, index}
	}

	// Fresh named variable
	index = p.varIndex
	p.varIndex++
	p.nameMap[name] = index
	v := &astVar{t.lineno, name, index}
	p.vars = append(p.vars, v)
	return v
}

func getVars(l yyLexer) []*astVar {
	p := l.(*tokenizer2).ctx
	vs := p.vars
	p.varIndex = 0
	p.vars = p.vars[0:0]
	for k := range p.nameMap {
		delete(p.nameMap, k)
	}
	return vs
}

//line yacctab:1
var yyExca = [...]int8{
	-1, 1,
	1, -1,
	-2, 0,
}

const yyPrivate = 57344

const yyLast = 38

var yyAct = [...]int8{
	19, 26, 31, 11, 26, 25, 18, 21, 11, 10,
	15, 16, 32, 26, 22, 24, 23, 7, 8, 10,
	15, 16, 20, 14, 29, 9, 13, 30, 27, 28,
	17, 12, 6, 5, 4, 3, 2, 1,
}

var yyPact = [...]int16{
	-1000, -1000, 5, -1000, -1000, -1000, -1000, 15, 15, -5,
	6, 9, -1000, -1000, -1000, -1000, -1000, 4, -6, 9,
	-1000, 15, 15, 15, -1000, -1000, 15, -9, 3, -1000,
	9, -1000, -1000,
}

var yyPgo = [...]int8{
	0, 37, 36, 35, 34, 33, 32, 6, 0, 22,
	31, 26, 23,
}

var yyR1 = [...]int8{
	0, 1, 2, 2, 3, 3, 3, 4, 5, 6,
	8, 8, 8, 8, 7, 7, 9, 9, 10, 11,
	12,
}

var yyR2 = [...]int8{
	0, 1, 0, 2, 1, 1, 1, 3, 3, 4,
	1, 1, 1, 1, 1, 3, 4, 3, 1, 1,
	1,
}

var yyChk = [...]int16{
	-1000, -1, -2, -3, -4, -5, -6, 12, 13, -9,
	4, -8, -10, -11, -12, 5, 6, -9, -7, -8,
	-9, 12, 8, 7, 11, 11, 10, -7, -7, -8,
	-8, 11, 9,
}

var yyDef = [...]int8{
	2, -2, 1, 3, 4, 5, 6, 0, 0, 10,
	18, 0, 11, 12, 13, 19, 20, 10, 0, 14,
	10, 0, 0, 0, 7, 8, 0, 0, 0, 17,
	15, 9, 16,
}

var yyTok1 = [...]int8{
	1,
}

var yyTok2 = [...]int8{
	2, 3, 4, 5, 6, 7, 8, 9, 10, 11,
	12, 13,
}

var yyTok3 = [...]int8{
	0,
}

var yyErrorMessages = [...]struct {
	state int
	token int
	msg   string
}{}

//line yaccpar:1

/*	parser for yacc output	*/

var (
	yyDebug        = 0
	yyErrorVerbose = false
)

type yyLexer interface {
	Lex(lval *yySymType) int
	Error(s string)
}

type yyParser interface {
	Parse(yyLexer) int
	Lookahead() int
}

type yyParserImpl struct {
	lval  yySymType
	stack [yyInitialStackSize]yySymType
	char  int
}

func (p *yyParserImpl) Lookahead() int {
	return p.char
}

func yyNewParser() yyParser {
	return &yyParserImpl{}
}

const yyFlag = -1000

func yyTokname(c int) string {
	if c >= 1 && c-1 < len(yyToknames) {
		if yyToknames[c-1] != "" {
			return yyToknames[c-1]
		}
	}
	return __yyfmt__.Sprintf("tok-%v", c)
}

func yyStatname(s int) string {
	if s >= 0 && s < len(yyStatenames) {
		if yyStatenames[s] != "" {
			return yyStatenames[s]
		}
	}
	return __yyfmt__.Sprintf("state-%v", s)
}

func yyErrorMessage(state, lookAhead int) string {
	const TOKSTART = 4

	if !yyErrorVerbose {
		return "syntax error"
	}

	for _, e := range yyErrorMessages {
		if e.state == state && e.token == lookAhead {
			return "syntax error: " + e.msg
		}
	}

	res := "syntax error: unexpected " + yyTokname(lookAhead)

	// To match Bison, suggest at most four expected tokens.
	expected := make([]int, 0, 4)

	// Look for shiftable tokens.
	base := int(yyPact[state])
	for tok := TOKSTART; tok-1 < len(yyToknames); tok++ {
		if n := base + tok; n >= 0 && n < yyLast && int(yyChk[int(yyAct[n])]) == tok {
			if len(expected) == cap(expected) {
				return res
			}
			expected = append(expected, tok)
		}
	}

	if yyDef[state] == -2 {
		i := 0
		for yyExca[i] != -1 || int(yyExca[i+1]) != state {
			i += 2
		}

		// Look for tokens that we accept or reduce.
		for i += 2; yyExca[i] >= 0; i += 2 {
			tok := int(yyExca[i])
			if tok < TOKSTART || yyExca[i+1] == 0 {
				continue
			}
			if len(expected) == cap(expected) {
				return res
			}
			expected = append(expected, tok)
		}

		// If the default action is to accept or reduce, give up.
		if yyExca[i+1] != 0 {
			return res
		}
	}

	for i, tok := range expected {
		if i == 0 {
			res += ", expecting "
		} else {
			res += " or "
		}
		res += yyTokname(tok)
	}
	return res
}

func yylex1(lex yyLexer, lval *yySymType) (char, token int) {
	token = 0
	char = lex.Lex(lval)
	if char <= 0 {
		token = int(yyTok1[0])
		goto out
	}
	if char < len(yyTok1) {
		token = int(yyTok1[char])
		goto out
	}
	if char >= yyPrivate {
		if char < yyPrivate+len(yyTok2) {
			token = int(yyTok2[char-yyPrivate])
			goto out
		}
	}
	for i := 0; i < len(yyTok3); i += 2 {
		token = int(yyTok3[i+0])
		if token == char {
			token = int(yyTok3[i+1])
			goto out
		}
	}

out:
	if token == 0 {
		token = int(yyTok2[1]) /* unknown char */
	}
	if yyDebug >= 3 {
		__yyfmt__.Printf("lex %s(%d)\n", yyTokname(token), uint(char))
	}
	return char, token
}

func yyParse(yylex yyLexer) int {
	return yyNewParser().Parse(yylex)
}

func (yyrcvr *yyParserImpl) Parse(yylex yyLexer) int {
	var yyn int
	var yyVAL yySymType
	var yyDollar []yySymType
	_ = yyDollar // silence set and not used
	yyS := yyrcvr.stack[:]

	Nerrs := 0   /* number of errors */
	Errflag := 0 /* error recovery flag */
	yystate := 0
	yyrcvr.char = -1
	yytoken := -1 // yyrcvr.char translated into internal numbering
	defer func() {
		// Make sure we report no lookahead when not parsing.
		yystate = -1
		yyrcvr.char = -1
		yytoken = -1
	}()
	yyp := -1
	goto yystack

ret0:
	return 0

ret1:
	return 1

yystack:
	/* put a state and value onto the stack */
	if yyDebug >= 4 {
		__yyfmt__.Printf("char %v in %v\n", yyTokname(yytoken), yyStatname(yystate))
	}

	yyp++
	if yyp >= len(yyS) {
		nyys := make([]yySymType, len(yyS)*2)
		copy(nyys, yyS)
		yyS = nyys
	}
	yyS[yyp] = yyVAL
	yyS[yyp].yys = yystate

yynewstate:
	yyn = int(yyPact[yystate])
	if yyn <= yyFlag {
		goto yydefault /* simple state */
	}
	if yyrcvr.char < 0 {
		yyrcvr.char, yytoken = yylex1(yylex, &yyrcvr.lval)
	}
	yyn += yytoken
	if yyn < 0 || yyn >= yyLast {
		goto yydefault
	}
	yyn = int(yyAct[yyn])
	if int(yyChk[yyn]) == yytoken { /* valid shift */
		yyrcvr.char = -1
		yytoken = -1
		yyVAL = yyrcvr.lval
		yystate = yyn
		if Errflag > 0 {
			Errflag--
		}
		goto yystack
	}

yydefault:
	/* default state action */
	yyn = int(yyDef[yystate])
	if yyn == -2 {
		if yyrcvr.char < 0 {
			yyrcvr.char, yytoken = yylex1(yylex, &yyrcvr.lval)
		}

		/* look through exception table */
		xi := 0
		for {
			if yyExca[xi+0] == -1 && int(yyExca[xi+1]) == yystate {
				break
			}
			xi += 2
		}
		for xi += 2; ; xi += 2 {
			yyn = int(yyExca[xi+0])
			if yyn < 0 || yyn == yytoken {
				break
			}
		}
		yyn = int(yyExca[xi+1])
		if yyn < 0 {
			goto ret0
		}
	}
	if yyn == 0 {
		/* error ... attempt to resume parsing */
		switch Errflag {
		case 0: /* brand new error */
			yylex.Error(yyErrorMessage(yystate, yytoken))
			Nerrs++
			if yyDebug >= 1 {
				__yyfmt__.Printf("%s", yyStatname(yystate))
				__yyfmt__.Printf(" saw %s\n", yyTokname(yytoken))
			}
			fallthrough

		case 1, 2: /* incompletely recovered error ... try again */
			Errflag = 3

			/* find a state where "error" is a legal shift action */
			for yyp >= 0 {
				yyn = int(yyPact[yyS[yyp].yys]) + yyErrCode
				if yyn >= 0 && yyn < yyLast {
					yystate = int(yyAct[yyn]) /* simulate a shift of "error" */
					if int(yyChk[yystate]) == yyErrCode {
						goto yystack
					}
				}

				/* the current p has no shift on "error", pop stack */
				if yyDebug >= 2 {
					__yyfmt__.Printf("error recovery pops state %d\n", yyS[yyp].yys)
				}
				yyp--
			}
			/* there is no state on the stack with an error shift ... abort */
			goto ret1

		case 3: /* no shift yet; clobber input char */
			if yyDebug >= 2 {
				__yyfmt__.Printf("error recovery discards %s\n", yyTokname(yytoken))
			}
			if yytoken == yyEofCode {
				goto ret1
			}
			yyrcvr.char = -1
			yytoken = -1
			goto yynewstate /* try again in the same state */
		}
	}

	/* reduction by production yyn */
	if yyDebug >= 2 {
		__yyfmt__.Printf("reduce %v in:\n\t%v\n", yyn, yyStatname(yystate))
	}

	yynt := yyn
	yypt := yyp
	_ = yypt // guard against "declared and not used"

	yyp -= int(yyR2[yyn])
	// yyp is now the index of $0. Perform the default action. Iff the
	// reduced production is ε, $1 is possibly out of range.
	if yyp+1 >= len(yyS) {
		nyys := make([]yySymType, len(yyS)*2)
		copy(nyys, yyS)
		yyS = nyys
	}
	yyVAL = yyS[yyp+1]

	/* consult goto table to find next state */
	yyn = int(yyR1[yyn])
	yyg := int(yyPgo[yyn])
	yyj := yyg + yyS[yyp].yys + 1

	if yyj >= yyLast {
		yystate = int(yyAct[yyg])
	} else {
		yystate = int(yyAct[yyj])
		if int(yyChk[yystate]) != -yyn {
			yystate = int(yyAct[yyg])
		}
	}
	// dummy call; replaced with literal code
	switch yynt {

	case 1:
		yyDollar = yyS[yypt-1 : yypt+1]
//line grammar.y:95
		{
			setResult(yylex, yyDollar[1].phrases)
		}
	case 2:
		yyDollar = yyS[yypt-0 : yypt+1]
//line grammar.y:100
		{
			yyVAL.phrases = []astPhrase{}
		}
	case 3:
		yyDollar = yyS[yypt-2 : yypt+1]
//line grammar.y:104
		{
			yyVAL.phrases = append(yyDollar[1].phrases, yyDollar[2].phrase)
		}
	case 7:
		yyDollar = yyS[yypt-3 : yypt+1]
//line grammar.y:110
		{
			vars := getVars(yylex)
			if len(vars) != 0 {
				yylex.Error("Facts should not have free variables")
				// TODO: how to recover here?
			}
			yyVAL.phrase = &astFact{yyDollar[2].term}
		}
	case 8:
		yyDollar = yyS[yypt-3 : yypt+1]
//line grammar.y:120
		{
			yyVAL.phrase = &astQuery{getVars(yylex), yyDollar[2].terms}
		}
	case 9:
		yyDollar = yyS[yypt-4 : yypt+1]
//line grammar.y:125
		{
			yyVAL.phrase = &astRule{getVars(yylex), yyDollar[1].term, yyDollar[3].terms}
		}
	case 14:
		yyDollar = yyS[yypt-1 : yypt+1]
//line grammar.y:131
		{
			yyVAL.terms = []astTerm{yyDollar[1].term}
		}
	case 15:
		yyDollar = yyS[yypt-3 : yypt+1]
//line grammar.y:135
		{
			yyVAL.terms = append(yyDollar[1].terms, yyDollar[3].term)
		}
	case 16:
		yyDollar = yyS[yypt-4 : yypt+1]
//line grammar.y:140
		{
			yyVAL.term = &astStruct{lineno(yylex), yyDollar[1].name, yyDollar[3].terms}
		}
	case 17:
		yyDollar = yyS[yypt-3 : yypt+1]
//line grammar.y:144
		{
			yyVAL.term = &astStruct{lineno(yylex), yyDollar[2].name, []astTerm{yyDollar[1].term, yyDollar[3].term}}
		}
	case 18:
		yyDollar = yyS[yypt-1 : yypt+1]
//line grammar.y:149
		{
			yyVAL.term = &astAtom{lineno(yylex), yyDollar[1].name}
		}
	case 19:
		yyDollar = yyS[yypt-1 : yypt+1]
//line grammar.y:154
		{
			val, err := strconv.ParseInt(yyDollar[1].name, 10, 64)
			if err != nil {
				yylex.Error("numeric overflow")
				// TODO: how to recover here?
			}
			yyVAL.term = &astNumber{lineno(yylex), val}
		}
	case 20:
		yyDollar = yyS[yypt-1 : yypt+1]
//line grammar.y:164
		{
			yyVAL.term = newVariable(yylex, yyDollar[1].name)
		}
	}
	goto yystack /* stack new state and value */
}
